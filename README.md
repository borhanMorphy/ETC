# Encoding Long and Structured Inputs in Transformers

<!-- TODO add badges -->

<img src="/resources/ETC.png"/>

## Contents

- [Installation](#installation)
- [References](#references)
- [Citations](#citations)

## Installation

```
git clone https://github.com/borhanMorphy/ETC.git
cd ETC
pip install .
```

## References

- [Official Implementation](https://github.com/google-research/google-research/tree/master/etcmodel)
- [Paper](https://arxiv.org/pdf/1703.05175.pdf)

## Citations

```bibtex
@inproceedings{ainslie2020etc,
  title={ETC: Encoding Long and Structured Data in Transformers},
  author={Joshua Ainslie and Santiago Onta{\~n}{\'o}n and Chris Alberti and Vaclav Cvicek and Zachary Fisher and Philip Pham and Anirudh Ravula and Sumit Sanghai and Qifan Wang and Li Yang},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020)},
  year={2020}
}
```
